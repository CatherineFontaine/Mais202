# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UD0vpDMANT5cKvyyDoaQxHDjEg853fve
"""

import matplotlib.pyplot as plt
import numpy as np
import PIL
import tensorflow as tf
from google.colab import drive
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
import pandas as pd
import glob
from IPython.display import display, Image

"""Following the way describe in https://www.tensorflow.org/tutorials/images/classification"""

from google.colab import drive
drive.mount("/content/gdrive")

sample_images = glob.glob('/content/gdrive/My Drive/good_bird/MERLIN/*.jpg')[:5]
for file_path in sample_images:
  display(Image(file_path))

data_dir='/content/gdrive/My Drive/good_bird/'

img_height = 224
img_width = 224

"""## 1) data augmentation"""

#I want to increase my dataset since i have only 200 images per species
import cv2
Asian_green_bee_eater=glob.glob('/content/gdrive/My Drive/good_bird/ASIAN GREEN BEE EATER/*.jpg')
k=1
for i in Asian_green_bee_eater:
  image=cv2.imread(i)
  img_flip=cv2.flip(image, 1)
  cv2.imwrite('/content/gdrive/My Drive/good_bird/ASIAN GREEN BEE EATER/flip_'+str(k)+'.jpg', img_flip)
  img_adj= cv2.convertScaleAbs(image,1.5, 1.5)
  cv2.imwrite('/content/gdrive/My Drive/good_bird/ASIAN GREEN BEE EATER/brigth_'+str(k)+'.jpg', img_adj)
  k=k+1

Bufflehead=glob.glob('/content/gdrive/My Drive/good_bird/BUFFLEHEAD/*.jpg')
k=1
for i in Bufflehead:
  image=cv2.imread(i)
  img_flip=cv2.flip(image, 1)
  cv2.imwrite('/content/gdrive/My Drive/good_bird/BUFFLEHEAD/flip_'+str(k)+'.jpg', img_flip)
  img_adj= cv2.convertScaleAbs(image,1.5, 1.5)
  cv2.imwrite('/content/gdrive/My Drive/good_bird/BUFFLEHEAD/brigth_'+str(k)+'.jpg', img_adj)
  k=k+1

Caspian_tern=glob.glob('/content/gdrive/My Drive/good_bird/CASPIAN TERN/*.jpg')
k=1
for i in Caspian_tern:
  image=cv2.imread(i)
  img_flip=cv2.flip(image, 1)
  cv2.imwrite('/content/gdrive/My Drive/good_bird/CASPIAN TERN/flip_'+str(k)+'.jpg', img_flip)
  img_adj= cv2.convertScaleAbs(image,1.5, 1.5)
  cv2.imwrite('/content/gdrive/My Drive/good_bird/CASPIAN TERN/brigth_'+str(k)+'.jpg', img_adj)
  k=k+1

Crimson_sunbird=glob.glob('/content/gdrive/My Drive/good_bird/CRIMSON SUNBIRD/*.jpg')
k=1
for i in Crimson_sunbird:
  image=cv2.imread(i)
  img_flip=cv2.flip(image, 1)
  cv2.imwrite('/content/gdrive/My Drive/good_bird/CRIMSON SUNBIRD/flip_'+str(k)+'.jpg', img_flip)
  img_adj= cv2.convertScaleAbs(image,1.5, 1.5)
  cv2.imwrite('/content/gdrive/My Drive/good_bird/CRIMSON SUNBIRD/brigth_'+str(k)+'.jpg', img_adj)
  k=k+1

Eastern_yellow_robin=glob.glob('/content/gdrive/My Drive/good_bird/EASTERN YELLOW ROBIN/*.jpg')
k=1
for i in Eastern_yellow_robin:
  image=cv2.imread(i)
  img_flip=cv2.flip(image, 1)
  cv2.imwrite('/content/gdrive/My Drive/good_bird/EASTERN YELLOW ROBIN/flip_'+str(k)+'.jpg', img_flip)
  img_adj= cv2.convertScaleAbs(image,1.5, 1.5)
  cv2.imwrite('/content/gdrive/My Drive/good_bird/EASTERN YELLOW ROBIN/brigth_'+str(k)+'.jpg', img_adj)
  k=k+1

Greater_prairie_chicken=glob.glob('/content/gdrive/My Drive/good_bird/GREATER PRAIRIE CHICKEN/*.jpg')
k=1
for i in Greater_prairie_chicken:
  image=cv2.imread(i)
  img_flip=cv2.flip(image, 1)
  cv2.imwrite('/content/gdrive/My Drive/good_bird/GREATER PRAIRIE CHICKEN/flip_'+str(k)+'.jpg', img_flip)
  img_adj= cv2.convertScaleAbs(image,1.5, 1.5)
  cv2.imwrite('/content/gdrive/My Drive/good_bird/GREATER PRAIRIE CHICKEN/brigth_'+str(k)+'.jpg', img_adj)
  k=k+1

Merlin=glob.glob('/content/gdrive/My Drive/good_bird/MERLIN/*.jpg')
k=1
for i in Merlin:
  image=cv2.imread(i)
  img_flip=cv2.flip(image, 1)
  cv2.imwrite('/content/gdrive/My Drive/good_bird/MERLIN/flip_'+str(k)+'.jpg', img_flip)
  img_adj= cv2.convertScaleAbs(image,1.5, 1.5)
  cv2.imwrite('/content/gdrive/My Drive/good_bird/MERLIN/brigth_'+str(k)+'.jpg', img_adj)
  k=k+1

Military_macaw=glob.glob('/content/gdrive/My Drive/good_bird/MILITARY MACAW/*.jpg')
k=1
for i in Military_macaw:
  image=cv2.imread(i)
  img_flip=cv2.flip(image, 1)
  cv2.imwrite('/content/gdrive/My Drive/good_bird/MILITARY MACAW/flip_'+str(k)+'.jpg', img_flip)
  img_adj= cv2.convertScaleAbs(image,1.5, 1.5)
  cv2.imwrite('/content/gdrive/My Drive/good_bird/MILITARY MACAW/brigth_'+str(k)+'.jpg', img_adj)
  k=k+1

Ovenbird=glob.glob('/content/gdrive/My Drive/good_bird/OVENBIRD/*.jpg')
k=1
for i in Ovenbird:
  image=cv2.imread(i)
  img_flip=cv2.flip(image, 1)
  cv2.imwrite('/content/gdrive/My Drive/good_bird/OVENBIRD/flip_'+str(k)+'.jpg', img_flip)
  img_adj= cv2.convertScaleAbs(image,1.5, 1.5)
  cv2.imwrite('/content/gdrive/My Drive/good_bird/OVENBIRD/brigth_'+str(k)+'.jpg', img_adj)
  k=k+1

Oyster_catcher=glob.glob('/content/gdrive/My Drive/good_bird/OYSTER CATCHER/*.jpg')
k=1
for i in Oyster_catcher:
  image=cv2.imread(i)
  img_flip=cv2.flip(image, 1)
  cv2.imwrite('/content/gdrive/My Drive/good_bird/OYSTER CATCHER/flip_'+str(k)+'.jpg', img_flip)
  img_adj= cv2.convertScaleAbs(image,1.5, 1.5)
  cv2.imwrite('/content/gdrive/My Drive/good_bird/OYSTER CATCHER/brigth_'+str(k)+'.jpg', img_adj)
  k=k+1

Wood_Duck=glob.glob('/content/gdrive/My Drive/good_bird/WOOD DUCK/*.jpg')
k=1
for i in Wood_Duck:
  image=cv2.imread(i)
  img_flip=cv2.flip(image, 1)
  cv2.imwrite('/content/gdrive/My Drive/good_bird/WOOD DUCK/flip_'+str(k)+'.jpg', img_flip)
  img_adj= cv2.convertScaleAbs(image,1.5, 1.5)
  cv2.imwrite('/content/gdrive/My Drive/good_bird/WOOD DUCK/brigth_'+str(k)+'.jpg', img_adj)
  k=k+1

"""## 1) Train the data"""

train_ds =  tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.15,
  subset="training",
  seed=456,
  image_size=(img_height, img_width))

val_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.15,
  subset="validation",
  seed=456,
  image_size=(img_height, img_width))

class_names = train_ds.class_names
print(class_names)

AUTOTUNE = tf.data.AUTOTUNE

#this help reduce the training time 
train_ds=train_ds.prefetch(AUTOTUNE)
valid_ds=val_ds.prefetch(AUTOTUNE) 
train_ds=train_ds.cache()
valid_ds=val_ds.cache()

num_classes = len(class_names)

model = Sequential([
  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),
  layers.Conv2D(16, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(32, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(64, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(128, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(256, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Flatten(),
  layers.Dense(256, activation='relu'),
  layers.Dense(num_classes)
])

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
#adam is a gradient descent algorithm

epochs=7
history = model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=epochs
)

model.save_weights('/content/gdrive/My Drive/good_bird/my_model.h5')